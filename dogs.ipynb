{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3KiInenTggW"
      },
      "source": [
        "# Frame the problem and look at the big picture "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8nVBu4HTggY"
      },
      "source": [
        "Chewy wants to develop a dog door that only opens for your pet. They would like an initial system that can recognize the breed of the dog. The door should not open if the dog is not the same breed as your dog. They have provided us with over 20,000 images of 120 different breeds of dogs. They want a high precision so that no other dogs (or mistaken creatures) are able to enter the door. Their current products require the pet to have chip or a special collar. They would like to have a new system that requires no external devices, this is a proof of concept problem because if they can't predict breed, they may not even be able to detect one dog properly.\n",
        "\n",
        "This will be a supervised offline classification problem. We will use precision because we want to lower the amount of False Positives and keep True Positives up. (It would be acceptable for the door not to open every single time, but it is not acceptable to open for the incorrect breed.)\n",
        "\n",
        "Since our system is sort of a starting point for their ultimate goal, we will shoot for 85% precision as well as a high accuracy (85%). Since this is more of a proof of concept though, we have some leeway with precision.\n",
        "\n",
        "The MNIST problems are similar and we can reuse some code from notebooks.\n",
        "\n",
        "There are no experts available to us.\n",
        "\n",
        "The manual solution is the use of a chip/collar system.\n",
        "Look for body shape, face shape, color\n",
        "\n",
        "We assume the data is labelled correctly and not missing significant portions.\n",
        "We will resize the images to be the same size, but this could introduce other issues potentially. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhKLISt3c5XX",
        "outputId": "c5ae8fec-0ecd-4d94-a40c-d89bba419ca9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  756M  100  756M    0     0  31.3M      0  0:00:24  0:00:24 --:--:-- 28.7M\n"
          ]
        }
      ],
      "source": [
        "!curl vision.stanford.edu/aditya86/ImageNetDogs/images.tar --output images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAQ0ZPYfdV8A"
      },
      "outputs": [],
      "source": [
        "!tar -xf images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbQhozeHTggb",
        "outputId": "00db9619-9b85-4f1b-bdd2-4fcf7da37d0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "d098b0299a1e\n"
          ]
        }
      ],
      "source": [
        "!hostname"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3FUk36WGTgge"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import gc\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.model_selection import cross_val_predict, cross_val_score, GridSearchCV, train_test_split\n",
        "from sklearn.metrics import confusion_matrix, precision_score\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
        "\n",
        "from sklearn import set_config\n",
        "set_config(display='diagram')\n",
        "\n",
        "from matplotlib import style\n",
        "style.use('dark_background')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5n4gQ9fNTmBQ"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qA5dPXJoTggg"
      },
      "outputs": [],
      "source": [
        "# def load_images_and_labels(categories, fpath):\n",
        "#     img_lst=[]\n",
        "#     labels=[]\n",
        "#     for index, category in enumerate(categories):\n",
        "#         for image_name in os.listdir(fpath+\"/\"+category):\n",
        "#             img = cv2.imread(fpath+\"/\"+category+\"/\"+image_name)\n",
        "#             img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "#             img_array = Image.fromarray(img, 'RGB')\n",
        "#             resized_img = img_array.resize((227, 227))\n",
        "#             img_lst.append(np.array(resized_img))\n",
        "#             labels.append(index)\n",
        "\n",
        "#     images = np.array(img_lst).astype(np.float32)/255\n",
        "#     labels = np.array(labels).astype(np.int32)\n",
        "    \n",
        "#     return images, labels\n",
        "\n",
        "def display_rand_images(images, labels, names):\n",
        "    plt.figure(1 , figsize = (19 , 10))\n",
        "    for i in range(9):\n",
        "        r = np.random.randint(0 , images.shape[0] , 1)\n",
        "        \n",
        "        plt.subplot(3 , 3 , i+1)\n",
        "        plt.subplots_adjust(hspace = 0.3 , wspace = 0.3)\n",
        "        plt.imshow(images[r[0]])\n",
        "        \n",
        "        plt.title('Dog breed : {} ({})'.format(labels[r[0]], names[labels[r[0]]]))\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        \n",
        "    plt.show()\n",
        "\n",
        "def display_images(data, gray=False):\n",
        "    plt.figure(1 , figsize = (19 , 10))\n",
        "    for i in range(9):\n",
        "        r = np.random.randint(0 , data.shape[0] , 1)\n",
        "        plt.subplot(3 , 3 , i+1)\n",
        "        plt.subplots_adjust(hspace = 0.3 , wspace = 0.3)\n",
        "        if gray:\n",
        "            plt.imshow(data[r[0]], cmap='gray')\n",
        "        else:\n",
        "            plt.imshow(data[r[0]])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXEizS19PisT"
      },
      "outputs": [],
      "source": [
        "def load_images_and_labels(categories, fpath):\n",
        "    num_imgs = 0\n",
        "    for _, _, files in os.walk(fpath):\n",
        "        num_imgs += len(files)\n",
        "\n",
        "    imgs = np.empty((num_imgs, 3, 227, 227), dtype=np.float32)\n",
        "    labels = []\n",
        "    for index, category in enumerate(categories):\n",
        "        for image_name in os.listdir(fpath+\"/\"+category):\n",
        "            labels.append(index)\n",
        "            img = cv2.imread(fpath+\"/\"+category+\"/\"+image_name)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            img_array = Image.fromarray(img, 'RGB').resize((227, 227))\n",
        "            np.append(imgs, img_array)\n",
        "            gc.collect()\n",
        "\n",
        "\n",
        "    # images = np.array(img_lst).astype(np.float32)/255\n",
        "    labels = np.array(labels).astype(np.int32)\n",
        "    \n",
        "    return imgs, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgRZYgHpTggh"
      },
      "source": [
        "# Get the data \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EchbU1JZTggi"
      },
      "outputs": [],
      "source": [
        "# fpath = os.getcwd() + \"/archive/images/Images\"\n",
        "# fpath = os.getcwd() + \"/Images\"\n",
        "fpath = os.getcwd() + \"/images\"\n",
        "categories = os.listdir(fpath)\n",
        "names = [cat.split('-')[-1] for cat in categories]\n",
        "\n",
        "# This will take 2-3 minutes to run\n",
        "images, labels = load_images_and_labels(categories, fpath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXYbl3dATggk"
      },
      "outputs": [],
      "source": [
        "len(images), len(labels), len(names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wl4Mbqo3TDL"
      },
      "outputs": [],
      "source": [
        "type(images), type(labels), type(names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRVYIv-3Tggl"
      },
      "outputs": [],
      "source": [
        "display_rand_images(images, labels, names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29IZkx65Tggn"
      },
      "outputs": [],
      "source": [
        "# Shuffle the data\n",
        "n = np.arange(images.shape[0])\n",
        "np.random.seed(42)\n",
        "np.random.shuffle(n)\n",
        "images = images[n]\n",
        "labels = labels[n]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMpTCJ7OTggo"
      },
      "outputs": [],
      "source": [
        "X_train_, X_test_, y_train_, y_test_ = train_test_split(images, labels, test_size=0.2, random_state=42) # THIS IS THE DATA TO PROCESS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glMDZIpPP_sN"
      },
      "outputs": [],
      "source": [
        "X_val, X_test_, y_val, y_test_ = train_test_split(X_test_, y_test_, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZJHqoGCTggp"
      },
      "source": [
        "### Data for Explore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pI50389LImFg"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(X_train_.reshape(X_train_.shape[0], -1))\n",
        "df[\"labels\"] = y_train_\n",
        "df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5sMxBJmTggq"
      },
      "outputs": [],
      "source": [
        "train_set, test_set = train_test_split(df, test_size=0.2, random_state=42)\n",
        "# val_set, test_set = train_test_split(test_set, test_size=0.5, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RSf8y-FpDuRr"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = train_set.drop('labels', axis=1), train_set['labels']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcNt9XfYDv52"
      },
      "outputs": [],
      "source": [
        "train_subset = train_set.sample(n=1000, random_state=42)\n",
        "X_train_subset, y_train_subset = train_subset.drop('labels', axis=1), train_subset['labels']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_upTzeLvTggr"
      },
      "source": [
        "# Explore the data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4Ksk8AlZH5q"
      },
      "source": [
        "There wasn't much exploration to do because the ranges for values are all 0-255.\n",
        "There are no missing values because they are images and we have reshaped all of them to make processing easier. \n",
        "\n",
        "We did look into the correlations between the color channels and the target. We also looked at the grayscaled versions of the images.\n",
        "\n",
        "We performed PCA on both grayscaled and colored images and unsurprisingly, many of the values are not necessary to replicate the images. \n",
        "\n",
        "However, many images cannot be as accurately recovered because some images:\n",
        "  * are not of just one dog\n",
        "  * may not have the dog as the focus of the picture\n",
        "  * may have many humans in the image\n",
        "  * have odd angles\n",
        "\n",
        "These reasons will likely affect our model when we get there."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZewpBD4D1z5"
      },
      "source": [
        "### Need to use the dataframe for some of these"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5mXMdmCTggt"
      },
      "outputs": [],
      "source": [
        "# plot the first row of the train set as an image\n",
        "plt.imshow(X_train.iloc[0, :].values.reshape(227, 227, 3));\n",
        "plt.title('Dog breed : {} ({})'.format(y_train.iloc[0], names[y_train.iloc[0]]));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGp5xU4kTggu"
      },
      "outputs": [],
      "source": [
        "# This is about expected\n",
        "# X_train_.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DRUNvVwLTggu"
      },
      "outputs": [],
      "source": [
        "X_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-WWVi-DTggu"
      },
      "outputs": [],
      "source": [
        "X_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QYm6cA7Tggv"
      },
      "outputs": [],
      "source": [
        "# Look for the useless features\n",
        "c = pd.DataFrame({'breed': X_train.corrwith(y_train)})\n",
        "plt.figure(figsize=(12,50))\n",
        "sns.heatmap(c);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_p4kCV7lTggv"
      },
      "source": [
        "### Look at each color channel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bxub2eGSTggw"
      },
      "outputs": [],
      "source": [
        "# get each color channel\n",
        "r = X_train[X_train.columns[0::3]]\n",
        "g = X_train[X_train.columns[1::3]]\n",
        "b = X_train[X_train.columns[2::3]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6D_tDw76Tggw"
      },
      "outputs": [],
      "source": [
        "c = pd.DataFrame({'breed': r.corrwith(y_train)})\n",
        "plt.figure(figsize=(12,50))\n",
        "plt.title('Red channel')\n",
        "sns.heatmap(c);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTFPkfl5Tggx"
      },
      "outputs": [],
      "source": [
        "c = pd.DataFrame({'breed': g.corrwith(y_train)})\n",
        "plt.figure(figsize=(12,50))\n",
        "plt.title('Green channel')\n",
        "sns.heatmap(c);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcctdRItTggx"
      },
      "outputs": [],
      "source": [
        "c = pd.DataFrame({'breed': b.corrwith(y_train)})\n",
        "plt.figure(figsize=(12,50))\n",
        "plt.title('Blue channel')\n",
        "sns.heatmap(c);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVobmD4zTggy"
      },
      "source": [
        "## PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_R3oP1kTggy"
      },
      "outputs": [],
      "source": [
        "pca = PCA(n_components=0.99)\n",
        "pca.fit(X_train, y_train)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(pca.explained_variance_ratio_.cumsum())\n",
        "plt.xlabel('Number of features')\n",
        "plt.ylabel('Cumulative explained variance')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sH3deAAoTggy"
      },
      "outputs": [],
      "source": [
        "X_reduced = pca.fit_transform(X_train)\n",
        "X_recovered = pca.inverse_transform(X_reduced)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxsP4SevTggz"
      },
      "outputs": [],
      "source": [
        "# Let's see how good the recovery is\n",
        "display_images(X_recovered.reshape(X_train.shape[0], 227, 227, 3));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ionK7XbRTggz"
      },
      "outputs": [],
      "source": [
        "# Find importances of each feature\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "sorted(zip(rf.feature_importances_, X_train.columns), reverse=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLJUbr4vTgg0"
      },
      "source": [
        "## Try Grayscale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjUD1T2DFzBU"
      },
      "outputs": [],
      "source": [
        "# plot the first image\n",
        "plt.imshow(cv2.cvtColor(X_train.iloc[0,:].values.reshape(227, 227, 3)*255, cv2.COLOR_RGB2GRAY), cmap='gray');\n",
        "plt.title('Dog breed : {} ({})'.format(y_train.iloc[0], names[y_train.iloc[0]]));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTW_b2FyTgg1"
      },
      "outputs": [],
      "source": [
        "ims = X_train.iloc[:,:].values.reshape(X_train.shape[0], 227, 227, 3)*255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heAOHp8bTgg2"
      },
      "outputs": [],
      "source": [
        "X_subset_gray = np.array([cv2.cvtColor(im, cv2.COLOR_RGB2GRAY) for im in ims])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_nkJD_-Tgg2"
      },
      "outputs": [],
      "source": [
        "display_images(X_subset_gray, gray=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjYDPELJTgg2"
      },
      "outputs": [],
      "source": [
        "X_subset_gray = pd.DataFrame(X_subset_gray.reshape(X_subset_gray.shape[0], -1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zx1cHKKvTgg2"
      },
      "outputs": [],
      "source": [
        "# Look at the useless features\n",
        "c = pd.DataFrame({'breed': X_subset_gray.corrwith(y_train)})\n",
        "plt.figure(figsize=(12,50))\n",
        "sns.heatmap(c);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZlbiE6gTgg2"
      },
      "source": [
        "## Grayscale PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3_FnydeTgg3"
      },
      "outputs": [],
      "source": [
        "pca_gray = PCA(n_components=0.99)\n",
        "pca_gray.fit(X_subset_gray, y_train)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(pca_gray.explained_variance_ratio_.cumsum())\n",
        "plt.xlabel('Number of features')\n",
        "plt.ylabel('Cumulative explained variance')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCt-He2kTgg3"
      },
      "outputs": [],
      "source": [
        "X_gray_reduced = pca_gray.fit_transform(X_subset_gray)\n",
        "X_gray_recovered = pca_gray.inverse_transform(X_gray_reduced)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXOIAxO3Tgg3"
      },
      "outputs": [],
      "source": [
        "# Let's see how good the recovery is\n",
        "display_images(X_gray_recovered.reshape(X_train.shape[0], 227, 227), gray=True);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcXfiiJITgg4"
      },
      "outputs": [],
      "source": [
        "# Find importances of each feature\n",
        "rf_gray = RandomForestClassifier()\n",
        "rf_gray.fit(X_subset_gray, y_train)\n",
        "sorted(zip(rf_gray.feature_importances_, X_subset_gray.columns), reverse=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YztWqi7QTgg4"
      },
      "source": [
        "# Prepare the data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0kpcYMwTgg4"
      },
      "outputs": [],
      "source": [
        "def rgb_to_gray(X, reshape=True):\n",
        "    \"\"\"\n",
        "    Converts to grayscale array\n",
        "    TODO: write it better\n",
        "    \"\"\"\n",
        "    if isinstance(X, pd.DataFrame):\n",
        "      print(\"changing dataframe to grayscale\")\n",
        "      ims = X.values.reshape(X.shape[0], 227, 227, 3)\n",
        "      gray_ims = np.array([cv2.cvtColor(im, cv2.COLOR_RGB2GRAY) for im in ims])\n",
        "      if reshape:\n",
        "        return pd.DataFrame(gray_ims.reshape(X.shape[0], -1).reshape(X.shape[0], 227, 227, 1))\n",
        "      return pd.DataFrame(gray_ims.reshape(X.shape[0], -1))\n",
        "\n",
        "    elif isinstance(X, np.ndarray):\n",
        "      print(\"changing ndarray to grayscale\")\n",
        "      ims = X.reshape(X.shape[0], 227, 227, 3)\n",
        "      gray_ims = np.array([cv2.cvtColor(im, cv2.COLOR_RGB2GRAY) for im in ims])\n",
        "      if reshape:\n",
        "          return gray_ims.reshape(X.shape[0], -1).reshape(X.shape[0], 227, 227, 1)\n",
        "      return gray_ims.reshape(X.shape[0], -1)\n",
        "    else:\n",
        "      print(\"No changes\")\n",
        "      return X  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VdxHPnQLTgg5"
      },
      "outputs": [],
      "source": [
        "preprocessor_gray = Pipeline([\n",
        "    ('grayscale', FunctionTransformer(rgb_to_gray)),\n",
        "    ('pca', PCA(n_components=0.99)), # TODO: Look at IncrementalPCA, may need for full dataset\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XT1G36vmTgg6"
      },
      "outputs": [],
      "source": [
        "preprocessor_color = Pipeline([\n",
        "    ('pca', PCA(n_components=0.99)), # TODO: Look at IncrementalPCA, may need for full dataset\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clxAcvqaTgg7"
      },
      "source": [
        "# Short-list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UClngUMQTgg8"
      },
      "outputs": [],
      "source": [
        "def build_dog_network(input_shape=X_train_[0].shape, n_hidden_layers=5, n_neurons=100):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Input(shape=input_shape, name='input'))\n",
        "    for i in range(n_hidden_layers):\n",
        "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\", name=f'hidden_{i}'))\n",
        "    model.add(keras.layers.Dense(1, name='output'))\n",
        "    model.summary()\n",
        "    model.compile(optimizer=\"Nadam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmuPd7d3Tgg8"
      },
      "outputs": [],
      "source": [
        "def build_alexnet(is_gray=False):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    from keras.models import Sequential\n",
        "    from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout,BatchNormalization\n",
        "    if is_gray:\n",
        "      in_shape = (227,227,1)\n",
        "    else:\n",
        "      in_shape = (227,227,3)\n",
        "\n",
        "    model=Sequential()\n",
        "\n",
        "    #1 conv layer\n",
        "    model.add(Conv2D(filters=96,kernel_size=(11,11),strides=(4,4),padding=\"valid\",activation=\"relu\",input_shape=in_shape))\n",
        "\n",
        "    #1 max pool layer\n",
        "    model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
        "\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    #2 conv layer\n",
        "    model.add(Conv2D(filters=256,kernel_size=(5,5),strides=(1,1),padding=\"valid\",activation=\"relu\"))\n",
        "\n",
        "    #2 max pool layer\n",
        "    model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
        "\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    #3 conv layer\n",
        "    model.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding=\"valid\",activation=\"relu\"))\n",
        "\n",
        "    #4 conv layer\n",
        "    model.add(Conv2D(filters=384,kernel_size=(3,3),strides=(1,1),padding=\"valid\",activation=\"relu\"))\n",
        "\n",
        "    #5 conv layer\n",
        "    model.add(Conv2D(filters=256,kernel_size=(3,3),strides=(1,1),padding=\"valid\",activation=\"relu\"))\n",
        "\n",
        "    #3 max pool layer\n",
        "    model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))\n",
        "\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    #1 dense layer\n",
        "    model.add(Dense(4096,input_shape=in_shape,activation=\"relu\"))\n",
        "\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    #2 dense layer\n",
        "    model.add(Dense(4096,activation=\"relu\"))\n",
        "\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    #3 dense layer\n",
        "    model.add(Dense(1000,activation=\"relu\"))\n",
        "\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    #output layer\n",
        "    model.add(Dense(20,activation=\"softmax\"))\n",
        "\n",
        "    model.summary()\n",
        "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LEPdOAkTgg9"
      },
      "source": [
        "## Gray-scale"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGGOUbIiTgg9"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKX4nHjoTgg9"
      },
      "outputs": [],
      "source": [
        "# TODO: issue with preprocessor\n",
        "# rf_gray_pipeline = Pipeline([\n",
        "#     ('preprocessor', preprocessor_gray),\n",
        "#     ('classifier', RandomForestClassifier())\n",
        "# ]).fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnKZX3UbTgg-"
      },
      "outputs": [],
      "source": [
        "# rf_gray_scores = cross_val_score(rf_gray_pipeline, X_train, y_train, scoring=\"accuracy\")\n",
        "# rf_gray_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLTiq2RKTgg-"
      },
      "source": [
        "### Extra Trees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21mzQfEoTgg_"
      },
      "outputs": [],
      "source": [
        "# TODO: Issue with preprocessor\n",
        "# et_gray_pipeline = Pipeline([\n",
        "#         ('preprocessor', preprocessor_gray),\n",
        "#         ('classifier', ExtraTreesClassifier())\n",
        "# ]).fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RF195lcTgg_"
      },
      "outputs": [],
      "source": [
        "# et_gray_scores = cross_val_score(et_gray_pipeline, X_train, y_train, scoring=\"accuracy\")\n",
        "# et_gray_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1r5dHI8TghA"
      },
      "source": [
        "### Gray Neural Nets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ah2H0T5TghA"
      },
      "source": [
        "#### Our Own Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEdkVyU0TghA"
      },
      "outputs": [],
      "source": [
        "# nn_grey_clf = keras.wrappers.scikit_learn.KerasClassifier(build_dog_network, input_shape=X_train_.shape[1]//3, n_hidden_layers=5, n_neurons=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4HVjjAPTghB"
      },
      "outputs": [],
      "source": [
        "# nn_grey = Pipeline([\n",
        "#     ('grayscale', FunctionTransformer(rgb_to_gray)),\n",
        "#     ('classifier', nn_grey_clf),\n",
        "# ]).fit(X_train_, y_train_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8twBUS9TghB"
      },
      "outputs": [],
      "source": [
        "# nn_cust_grey_scores = cross_val_score(nn_grey, X_train_, y_train_, scoring=\"accuracy\")\n",
        "# nn_cust_grey_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5lfSwfCTghB"
      },
      "source": [
        "#### AlexNet for Grey Scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQn5F5wnTghB"
      },
      "outputs": [],
      "source": [
        "alexnet_grey = keras.wrappers.scikit_learn.KerasClassifier(build_alexnet, is_gray=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDky4v7UTghC"
      },
      "outputs": [],
      "source": [
        "alexnet_grey.fit( rgb_to_gray(X_train_), y_train_, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZspMlBK4Spm"
      },
      "outputs": [],
      "source": [
        "val_pred_grey = alexnet_grey.predict(rgb_to_gray(X_val))\n",
        "val_pred_grey.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0mTHH3k4aX_"
      },
      "outputs": [],
      "source": [
        "plt.figure(1, figsize=(19, 10))\n",
        "\n",
        "for i in range(9):\n",
        "    r = np.random.randint(0, X_val.shape[0], 1)\n",
        "    \n",
        "    plt.subplot(3, 3, i+1)\n",
        "    plt.subplots_adjust(hspace = 0.3, wspace = 0.3)\n",
        "    \n",
        "    plt.imshow(X_val[r[0]])\n",
        "    plt.title('Actual = {} ({}), \\nPredicted = {} ({})'.format(y_val[r[0]], names[y_val[r[0]]], \n",
        "                                                               val_pred_grey[r[0]], names[val_pred_grey[r[0]]]))\n",
        "    plt.xticks([]) , plt.yticks([])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4CWLUDv4fhG"
      },
      "outputs": [],
      "source": [
        "score_grey = sum(y_val == val_pred_grey) / X_val.shape[0]\n",
        "score_grey"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orv1Tt6MTghD"
      },
      "source": [
        "## Color"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tkqj30CuTghE"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MXhCsWITghE"
      },
      "outputs": [],
      "source": [
        "rf_color_pipeline = Pipeline([\n",
        "    ('classifier', RandomForestClassifier())\n",
        "]).fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94j398-2TghF"
      },
      "outputs": [],
      "source": [
        "rf_color_scores = cross_val_score(rf_color_pipeline, X_train, y_train, scoring=\"accuracy\")\n",
        "rf_color_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijyqc7QkTghG"
      },
      "source": [
        "### Extra Trees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXg9Ysp3TghH"
      },
      "outputs": [],
      "source": [
        "et_color_pipeline = Pipeline([\n",
        "        ('classifier', ExtraTreesClassifier())\n",
        "]).fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUj4cJfmTghH"
      },
      "outputs": [],
      "source": [
        "et_color_scores = cross_val_score(et_color_pipeline, X_train, y_train, scoring=\"accuracy\")\n",
        "et_color_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY_hrkq3TghI"
      },
      "source": [
        "### Color Neural Nets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWa62dVyTghI"
      },
      "source": [
        "#### Our Own Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtBrSQmLTghI"
      },
      "outputs": [],
      "source": [
        "# color_nn = keras.wrappers.scikit_learn.KerasClassifier(build_dog_network, input_shape=(227,227,3), n_hidden_layers=5, n_neurons=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDTPDwwGTghI"
      },
      "outputs": [],
      "source": [
        "# color_nn.fit(X_train_, y_train_, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5WE_TC7TghJ"
      },
      "outputs": [],
      "source": [
        "# nn_cust_color_scores = cross_val_score(color_nn, X_train_, y_train_, scoring=\"accuracy\")\n",
        "# nn_cust_color_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucHOHc8FTghJ"
      },
      "source": [
        "#### AlexNet for colored"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30sYs4DnTghK"
      },
      "outputs": [],
      "source": [
        "alexnet_color = keras.wrappers.scikit_learn.KerasClassifier(build_alexnet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWW2p8UmTghK"
      },
      "outputs": [],
      "source": [
        "alexnet_color.fit(X_train_, y_train_, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "httPlIZmTghK"
      },
      "outputs": [],
      "source": [
        "val_pred_color = alexnet_color.predict(X_val)\n",
        "val_pred_color.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4I65eta9RSQp"
      },
      "outputs": [],
      "source": [
        "plt.figure(1, figsize=(19, 10))\n",
        "\n",
        "for i in range(9):\n",
        "    r = np.random.randint(0, X_val.shape[0], 1)\n",
        "    \n",
        "    plt.subplot(3, 3, i+1)\n",
        "    plt.subplots_adjust(hspace = 0.3, wspace = 0.3)\n",
        "    \n",
        "    plt.imshow(X_val[r[0]])\n",
        "    plt.title('Actual = {} ({}), \\nPredicted = {} ({})'.format(y_val[r[0]], names[y_val[r[0]]], \n",
        "                                                               val_pred_color[r[0]], names[val_pred_color[r[0]]]))\n",
        "    plt.xticks([]) , plt.yticks([])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSg_4G_7TWac"
      },
      "outputs": [],
      "source": [
        "score_color = sum(y_val == val_pred_color) / X_val.shape[0]\n",
        "score_color"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-tYAD4CK3ZE"
      },
      "source": [
        "### Good Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQNNdBRaK7V-"
      },
      "outputs": [],
      "source": [
        "et_color_pipeline.get_params().keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gl4e9RqcLliD"
      },
      "outputs": [],
      "source": [
        "# the AlexNet color is likely the better choice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaocbM33TghK"
      },
      "source": [
        "# Fine-tune your models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aem93smvL5Iy"
      },
      "outputs": [],
      "source": [
        "# Try fine tuning the extra trees\n",
        "param_grid = [\n",
        "    { \n",
        "      'classifier__n_estimators': [180, 200, 220],\n",
        "      'classifier__max_depth': [10,12, 15], \n",
        "      'classifier__max_leaf_nodes': [10,12, 15], \n",
        "    }\n",
        "]\n",
        "\n",
        "search = GridSearchCV(et_color_pipeline, param_grid, cv=3, scoring='accuracy', verbose=1, n_jobs=-1);\n",
        "search.fit(X_train, y_train);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMaqjjYeMdkH"
      },
      "outputs": [],
      "source": [
        "models = zip(search.cv_results_['mean_test_score'], search.cv_results_['params'])\n",
        "for mean_score, params in sorted(models, key=lambda x: x[0], reverse=True)[:10]:\n",
        "    print(mean_score, params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRpS7jwrMhWi"
      },
      "outputs": [],
      "source": [
        "search.best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNEftG2xbDqe"
      },
      "source": [
        "Scores not improving much from grid search..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaiybixjTghL"
      },
      "source": [
        "# Present your solution "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FyXlyPcETghL"
      },
      "outputs": [],
      "source": [
        "final_pred = alexnet_color.predict(X_test_)\n",
        "final_score = sum(y_test_ == final_pred) / X_test_.shape[0]\n",
        "final_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ON4e8xfRb7_I"
      },
      "outputs": [],
      "source": [
        "plt.figure(1, figsize=(19, 10))\n",
        "\n",
        "for i in range(9):\n",
        "    r = np.random.randint(0, X_test_.shape[0], 1)\n",
        "    \n",
        "    plt.subplot(3, 3, i+1)\n",
        "    plt.subplots_adjust(hspace = 0.3, wspace = 0.3)\n",
        "    \n",
        "    plt.imshow(X_val[r[0]])\n",
        "    plt.title('Actual = {} ({}), \\nPredicted = {} ({})'.format(y_test_[r[0]], names[y_test_[r[0]]], \n",
        "                                                               final_pred[r[0]], names[final_pred[r[0]]]))\n",
        "    plt.xticks([]) , plt.yticks([])\n",
        "\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IShmA0UqcEO3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kvHJX-FYoR6"
      },
      "source": [
        "A few attempts at modifications to gridsearch were unable to yield better results than the defaults. We were unable to run sklearn models using grayscaled images (had a bug we didn't have time to track down)\n",
        "\n",
        "Therefore, our best model was the AlexNet using color which had a <mark>%</mark> precision on the test set and had <mark>% evaluate!!</mark> accuracy. \n",
        "This model slightly outperformed the one that used grayscale images.\n",
        "\n",
        "Our results were not great... Part of this is because we did not have enough memory to do lots of transformations. \n",
        "Ideally, we could add more transformations on the images (such as flipping them upside down, cropping, etc). Another issue is that there are a good chunk of not great images to begin with. Some images barely have a dog in them and some have multiple dogs. We also had to cut down the number of breeds we were doing (mostly due to memory constraints). We didn't check but the first 20 categories could have poorly distributed amounts of images, or the most difficult dogs to distinguish, (or outright the worst images). This could be part of the cause for our low scores. \n",
        "\n",
        "[see more here](https://docs.google.com/presentation/d/19PBfOdaeBKNb2NyIfJWTD0xQLSJ59Cuu5T2Bj3hKmw0/edit?usp=sharing)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "LLJUbr4vTgg0",
        "mZlbiE6gTgg2",
        "_ah2H0T5TghA",
        "iWa62dVyTghI"
      ],
      "machine_shape": "hm",
      "name": "dogs.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "14546760c827fd72838203d07fc6082afc8b5bae4fd1bdec1330a454e4872fe6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
